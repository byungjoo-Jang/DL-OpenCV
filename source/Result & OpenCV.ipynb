{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confirmed-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exact-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC - 종료\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "\n",
    "labels_dict={1:'smile', 0:'not smile'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('../data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('../data/capture1/trainer/trainer.yml')\n",
    "\n",
    "model = load_model('../data/capture1/093-0.1248.model')\n",
    "\n",
    "record = False\n",
    "face_filter = False \n",
    "user_detection = False\n",
    "smile_detection = False\n",
    "\n",
    "\"\"\"\n",
    "# 비디오 재생\n",
    "video_dir = \"../data/mask/\"\n",
    "video_name = \"girl.mp4\"\n",
    "cam=cv2.VideoCapture(video_dir + video_name)\n",
    "\"\"\"\n",
    "\n",
    "# 실시간 영상\n",
    "cam=cv2.VideoCapture(0)\n",
    "\n",
    "width = cam.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cam.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "id = 0, 1, 2, 3\n",
    "names = ['SY', 'JM', 'HS', 'BJ']\n",
    "\n",
    "s_mask = cv2.imread('../data/mask/7.jpg')\n",
    "a_mask = cv2.imread('../data/mask/8.jpg')\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"영상 끝 - 종료\")\n",
    "        break\n",
    "        \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_rects = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "    \n",
    "    if face_filter:\n",
    "        info = \"Face Filter ON\"\n",
    "        if user_detection:\n",
    "            info = \"Face Filter & User Detection ON\"\n",
    "            if smile_detection:\n",
    "                info = \"All Filter ON\"\n",
    "        elif smile_detection:\n",
    "            info = \"Face Filter & Smile Detection ON\"\n",
    "    elif user_detection:\n",
    "        info = \"User Detection ON\"\n",
    "        if smile_detection:\n",
    "                info = \"User Detection & Smile Detection ON\"\n",
    "    elif smile_detection:\n",
    "        info = \"Smile Detection ON\"\n",
    "    else:\n",
    "        info = \"All Filter OFF\"            \n",
    "    \n",
    "    cv2.putText(frame, info, (5,50), font, 2, (188, 237, 75),2)\n",
    "    \n",
    "    for (x, y, w, h) in face_rects:        \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=model.predict(reshaped)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "        \n",
    "        # 미소 인식\n",
    "        if smile_detection:\n",
    "            if(labels_dict[label] == 'smile'):\n",
    "                cv2.putText(\n",
    "                frame, \"{}: {:.2f}%\".format(labels_dict[label], np.max(result) * 100),\n",
    "                (x, y-10),\n",
    "                font,0.6,(255,0,216),2)\n",
    "            else:\n",
    "                cv2.putText(\n",
    "                frame, \"{}: {:.2f}%\".format(labels_dict[label], np.max(result) * 100),\n",
    "                (x, y-10),\n",
    "                font,0.6,(216,255,0),2)\n",
    "            \n",
    "        # 사용자 인식\n",
    "        if user_detection:\n",
    "            id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        \n",
    "            if (confidence < 100):\n",
    "                id = names[id]\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            else:\n",
    "                id = \"unknown\"\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "            cv2.putText(frame, str(id), (x+90, y-45), font, 1, (0,216,255), 3)\n",
    "            cv2.putText(frame, str(confidence), (x+80,y-30), font, 0.5, (0,216,255), 1)            \n",
    "        \n",
    "        # 미소 인식 필터\n",
    "        if face_filter: \n",
    "            try:    \n",
    "                if(labels_dict[label] == 'smile'):\n",
    "                    if h > 0 and w > 0:\n",
    "                        x = int(x -w*0.1)\n",
    "                        y = int(y -h*0.05)\n",
    "                        w = int(1.2 * w)\n",
    "                        h = int(1.2 * h)\n",
    "\n",
    "                        frame_roi = frame[y:y + h, x:x + w]\n",
    "                        face_mask_small = cv2.resize(s_mask, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                        gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "                        ret, mask = cv2.threshold(gray_mask, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "                    mask_inv = cv2.bitwise_not(mask)\n",
    "                    masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n",
    "                    masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "                    frame[y:y + h, x:x + w] = cv2.add(masked_face, masked_frame)\n",
    "\n",
    "                else:\n",
    "                    if h > 0 and w > 0:\n",
    "                        x = int(x -w*0.1)\n",
    "                        y = int(y -h*0.05)\n",
    "                        w = int(1.2 * w)\n",
    "                        h = int(0.8 * h)\n",
    "\n",
    "                        frame_roi = frame[y:y + h, x:x + w]\n",
    "                        face_mask_small = cv2.resize(a_mask, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                        gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "                        ret, mask = cv2.threshold(gray_mask, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "                    mask_inv = cv2.bitwise_not(mask)\n",
    "                    masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n",
    "                    masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "                    frame[y:y + h, x:x + w] = cv2.add(masked_face, masked_frame)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "    \n",
    "    cv2.imshow('Project', frame)\n",
    "    \n",
    "    if key == 27: # ESC\n",
    "        print(\"ESC - 종료\")\n",
    "        break\n",
    "    elif key == 105: # i\n",
    "        face_filter = not face_filter\n",
    "    elif key == 117: # u\n",
    "        user_detection = not user_detection\n",
    "    elif key == 116: # t\n",
    "        smile_detection = not smile_detection\n",
    "    elif key == 99: # c\n",
    "        print(\"캡쳐\")\n",
    "        cv2.imwrite(\"../data/capture1/\" + str(now) + \".png\", frame)\n",
    "    elif key == 115: # s\n",
    "        print(\"녹화 시작\")\n",
    "        record = True\n",
    "        out = cv2.VideoWriter(\"../data/capture1/\" + str(now) + \".avi\", fourcc, 30, (int(width), int(height)))\n",
    "    elif key == 122: # z\n",
    "        print(\"녹화 중지\")\n",
    "        record = False\n",
    "        out.release()\n",
    "        \n",
    "    if record == True:\n",
    "        out.write(frame)\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
